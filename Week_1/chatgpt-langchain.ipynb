{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ChatGPT with LangChain\n",
    "\n",
    "This notebook provides a quick introduction to ChatGPT and related features supported in LangChain."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install these libraries before getting started. Ideally, you want to create a dedicated environment for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "import IPython\n",
    "from langchain.llms import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are adapting code from [here](https://langchain.readthedocs.io/en/latest/modules/chat/getting_started.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ROG\\AppData\\Roaming\\Python\\Python310\\site-packages\\langchain_core\\_api\\deprecation.py:141: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# chat mode instance\n",
    "chat = ChatOpenAI(temperature=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ChatGPT support different types of messages identifiable by the role. LangChain. Recall how we make a basic call to ChatGPT using `openai`? Here is an example:\n",
    "\n",
    "```python\n",
    "MODEL = \"gpt-3.5-turbo\"\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are an AI research assistant. You use a tone that is technical and scientific.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Hello, who are you?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Greeting! I am an AI research assistant. How can I help you today?\"},\n",
    "        {\"role\": \"user\", \"content\": \"Can you tell me about the creation of black holes?\"}\n",
    "    ],\n",
    "    temperature=0,\n",
    ")\n",
    "```\n",
    "\n",
    "LangChain supports these different types of messages, including a arbitrary role parameter (`ChatMessage`). Let's try: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Positive', response_metadata={'token_usage': {'completion_tokens': 1, 'prompt_tokens': 29, 'total_tokens': 30}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-03056789-baf5-4014-a7e1-aab465e7b21b-0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "USER_INPUT = \"I love programming.\"\n",
    "FINAL_PROMPT = \"\"\"Classify the text into neutral, negative or positive. \n",
    "\n",
    "Text: {user_input}. \n",
    "Sentiment:\"\"\"\n",
    "\n",
    "chat.invoke([HumanMessage(content=FINAL_PROMPT.format(user_input=USER_INPUT))])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try an example that involves a system instruction and a task provided by user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='positive', response_metadata={'token_usage': {'completion_tokens': 1, 'prompt_tokens': 49, 'total_tokens': 50}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-3d715707-561a-4b70-84d2-a2e40f31576d-0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant that can classify the sentiment of input texts. The labels you can use are positive, negative and neutral.\"),\n",
    "    HumanMessage(content=\"Classify the following sentence: I am doing brilliant today!\"),\n",
    "]\n",
    "\n",
    "chat.invoke(messages)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try another example that involves an exchange between a human and AI research assistant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Black holes are formed when massive stars exhaust their nuclear fuel and undergo a supernova explosion. If the core of the star is more than about three times the mass of the Sun, it collapses under its own gravity, forming a singularityâ€”a point of infinite density and zero volume. This singularity is surrounded by an event horizon, beyond which nothing, not even light, can escape due to the immense gravitational pull. This creates a region of spacetime from which no information or matter can escape, leading to the formation of a black hole.', response_metadata={'token_usage': {'completion_tokens': 108, 'prompt_tokens': 70, 'total_tokens': 178}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-ddc45ead-9c44-4969-9c54-3d04ccd75abb-0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"You are an AI research assistant. You use a tone that is technical and scientific.\"),\n",
    "    HumanMessage(content=\"Hello, who are you?\"),\n",
    "    AIMessage(content=\"Greeting! I am an AI research assistant. How can I help you today?\"),\n",
    "    HumanMessage(content=\"Can you tell me about the creation of black holes?\")\n",
    "]\n",
    "\n",
    "chat.invoke(messages)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is even a feature to batch these requests and generate response (using `chat.response()`) like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMResult(generations=[[ChatGeneration(text='Black holes are formed when massive stars exhaust their nuclear fuel and undergo a supernova explosion. If the core of the star is more than about three times the mass of the Sun, it collapses under its own gravity, forming a black hole. This collapse creates a region of spacetime with a gravitational field so intense that nothing, not even light, can escape from it. This point of infinite density at the center of a black hole is called a singularity. The boundary surrounding the singularity is known as the event horizon, beyond which nothing can escape the gravitational pull of the black hole.', generation_info={'finish_reason': 'stop', 'logprobs': None}, message=AIMessage(content='Black holes are formed when massive stars exhaust their nuclear fuel and undergo a supernova explosion. If the core of the star is more than about three times the mass of the Sun, it collapses under its own gravity, forming a black hole. This collapse creates a region of spacetime with a gravitational field so intense that nothing, not even light, can escape from it. This point of infinite density at the center of a black hole is called a singularity. The boundary surrounding the singularity is known as the event horizon, beyond which nothing can escape the gravitational pull of the black hole.', response_metadata={'token_usage': {'completion_tokens': 118, 'prompt_tokens': 70, 'total_tokens': 188}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-6ed54202-313e-46a5-9d60-09b784f513b6-0'))], [ChatGeneration(text='Dark matter is a hypothetical form of matter that is thought to make up approximately 27% of the total mass-energy content of the universe. It does not emit, absorb, or reflect light, making it invisible and detectable only through its gravitational effects on visible matter. Dark matter is believed to play a crucial role in the formation and structure of galaxies and the large-scale distribution of matter in the universe. Despite extensive research efforts, the exact nature of dark matter remains one of the most significant unsolved mysteries in astrophysics and cosmology.', generation_info={'finish_reason': 'stop', 'logprobs': None}, message=AIMessage(content='Dark matter is a hypothetical form of matter that is thought to make up approximately 27% of the total mass-energy content of the universe. It does not emit, absorb, or reflect light, making it invisible and detectable only through its gravitational effects on visible matter. Dark matter is believed to play a crucial role in the formation and structure of galaxies and the large-scale distribution of matter in the universe. Despite extensive research efforts, the exact nature of dark matter remains one of the most significant unsolved mysteries in astrophysics and cosmology.', response_metadata={'token_usage': {'completion_tokens': 109, 'prompt_tokens': 66, 'total_tokens': 175}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-94e104e4-547d-4953-9e43-9bd6d6fa3d35-0'))]], llm_output={'token_usage': {'completion_tokens': 227, 'prompt_tokens': 136, 'total_tokens': 363}, 'model_name': 'gpt-3.5-turbo'}, run=[RunInfo(run_id=UUID('6ed54202-313e-46a5-9d60-09b784f513b6')), RunInfo(run_id=UUID('94e104e4-547d-4953-9e43-9bd6d6fa3d35'))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_messages = [\n",
    "    [\n",
    "        SystemMessage(content=\"You are an AI research assistant. You use a tone that is technical and scientific.\"),\n",
    "        HumanMessage(content=\"Hello, who are you?\"),\n",
    "        AIMessage(content=\"Greeting! I am an AI research assistant. How can I help you today?\"),\n",
    "        HumanMessage(content=\"Can you tell me about the creation of black holes?\")\n",
    "    ],\n",
    "    [\n",
    "        SystemMessage(content=\"You are an AI research assistant. You use a tone that is technical and scientific.\"),\n",
    "        HumanMessage(content=\"Hello, who are you?\"),\n",
    "        AIMessage(content=\"Greeting! I am an AI research assistant. How can I help you today?\"),\n",
    "        HumanMessage(content=\"Can you explain the dark matter?\")\n",
    "    ]\n",
    "]\n",
    "\n",
    "chat.generate(batch_messages)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look at the examples above it might be easier to just use a prompt template. LangChain also supports. Let's try that below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"You are a helpful assistant that can classify the sentiment of input texts. The labels you can use are {sentiment_labels}. Classify the following sentence:\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
    "human_template = \"{user_input}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='positive', response_metadata={'token_usage': {'completion_tokens': 1, 'prompt_tokens': 50, 'total_tokens': 51}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-0de6d689-b940-4abb-b2f1-4c5a0c970269-0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "\n",
    "\n",
    "chat.invoke(chat_prompt.format_prompt(sentiment_labels=\"positive, negative, and neutral\", user_input=\"I am doing brilliant today!\").to_messages())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Neutral', response_metadata={'token_usage': {'completion_tokens': 1, 'prompt_tokens': 53, 'total_tokens': 54}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-ea9481ae-8d87-448a-ad9e-9e678e0ee358-0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.invoke(chat_prompt.format_prompt(sentiment_labels=\"positive, negative, and neutral\", user_input=\"Not sure what the weather is like today.\").to_messages())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "promptlecture",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f38e0373277d6f71ee44ee8fea5f1d408ad6999fda15d538a69a99a1665a839d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
